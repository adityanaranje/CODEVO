# ðŸš€ Advanced GitHub Repository RAG Q&A & Code Generation Bot

A sophisticated **Retrieval-Augmented Generation (RAG)** system that analyzes GitHub repositories, generates code, and answers questions using **Groq LLM**, **FAISS vector store**, and **HuggingFace embeddings**.

---

### ðŸŒ Try It Here [Live](https://codevo-aditya.streamlit.app/)

---
## âœ¨ Features

- **ðŸ“‚ Smart Repository Crawling**: Automatically processes multiple file types (Python, JavaScript, Java, C++, docs, etc.)  
- **ðŸ§  Language-Aware Processing**: Uses different text splitters based on file types for optimal chunking  
- **âš¡ Fast LLM Inference**: Powered by Groq for quick and accurate responses  
- **ðŸ” Efficient Vector Search**: FAISS for lightning-fast similarity search  
- **ðŸ“ Rich Source Attribution**: Shows exactly which files and code sections were used to answer questions  
- **ðŸ§© Repository Analysis**: Automated analysis of project structure and components  
- **ðŸ’» Code Generation**: Generate code snippets or functions using Groq LLM prompt templates  

---

## ðŸ“ File Structure

```
â”œâ”€â”€ config.py              # Configuration and API keys
â”œâ”€â”€ github_repository.py   # GitHub API handling and repository crawling
â”œâ”€â”€ document_processor.py  # Document chunking and processing
â”œâ”€â”€ embedding_manager.py   # FAISS vector store and embeddings
â”œâ”€â”€ llm_manager.py         # Groq LLM integration for GitHub repo
â”œâ”€â”€ code_generate.py       # Groq LLM for code generation using prompt templates
â”œâ”€â”€ rag_system.py          # Main RAG pipeline orchestration
â”œâ”€â”€ main.py                # Streamlit web application
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # This file
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configure API Keys

Edit `config.py` and replace the placeholder values:

```python
@dataclass
class Config:
    GROQ_API_KEY: str = "your_actual_groq_api_key_here"  # Get from https://console.groq.com/
    GITHUB_TOKEN: str = "your_actual_github_token_here"  # Optional but recommended
    # ... other settings
```

**Getting API Keys:**
- **ðŸ”‘ Groq API Key**: [Sign up here](https://console.groq.com/) and generate an API key  
- **ðŸ™ GitHub Token**: GitHub Settings â†’ Developer Settings â†’ Personal Access Tokens â†’ Generate new token (classic). Only requires public repo read access  

### 3ï¸âƒ£ Run the Application

```bash
streamlit run main.py
```

The app will open in your browser at `http://localhost:8501`

---

## ðŸ“ Usage

1. **Enter Repository URL**: Paste a GitHub repo URL in the sidebar (e.g., `https://github.com/langchain-ai/langchain`)  
2. **Process Repository**: Click **"Process Repository"** to crawl and analyze the repo. (May take a few minutes for large repos)  
3. **Ask Questions**: Once processed, ask questions like:  
   - "How does authentication work?"  
   - "What are the main components?"  
   - "How do I set up this project?"  
   - "Which testing frameworks are used?"  
4. **Generate Code**: Use the **Code Generation** tab to create functions, scripts, or snippets using Groq LLM prompt templates  
5. **View Sources**: Each answer shows the specific files and code sections that were used to generate the response  

---

## ðŸ— Architecture

### Core Components

- **GitHubRepository**: Handles GitHub API interactions, file filtering, and crawling  
- **AdvancedDocumentProcessor**: Applies language-specific text splitting  
- **EmbeddingManager**: Manages HuggingFace embeddings and FAISS vector store  
- **LLMManager**: Interfaces with Groq LLM for responses  
- **AdvancedRAGSystem**: Orchestrates the RAG pipeline  
- **CodeGenerator**: Generates code based on Groq LLM prompt templates  

### RAG + Code Generation Pipeline

1. **Repository Crawling**: Fetches files with intelligent filtering  
2. **Document Processing**: Splits documents using language-aware strategies  
3. **Embedding Creation**: Generates embeddings via HuggingFace  
4. **Vector Storage**: Stores embeddings in FAISS for similarity search  
5. **Query Processing**: Retrieves relevant chunks and generates responses using Groq  
6. **Code Generation**: Uses prompt templates to generate code snippets or functions  

---

## ðŸ—‚ Supported File Types

- **Programming Languages**: Python, JavaScript/TypeScript, Java, C/C++, C#, PHP, Ruby, Go, Rust, Scala, Kotlin  
- **Documentation**: Markdown, reStructuredText, Plain Text  
- **Configuration**: JSON, YAML, TOML, INI  
- **Web**: HTML, CSS, SCSS  
- **Special Files**: README, LICENSE, CHANGELOG, DOCKERFILE, MAKEFILE  

---

## âš™ï¸ Configuration Options (`config.py`)

- `CHUNK_SIZE`: Size of text chunks (default: 1000)  
- `CHUNK_OVERLAP`: Overlap between chunks (default: 200)  
- `TOP_K_RETRIEVAL`: Number of relevant chunks to retrieve (default: 5)  
- `TEMPERATURE`: LLM response randomness (default: 0.3)  
- `MAX_TOKENS`: Maximum response length (default: 2048)  

---

## âš ï¸ Troubleshooting

### Common Issues

1. **API Key Errors**: Ensure Groq API key is valid in `config.py`  
2. **Repository Access**: Some repos may be private or restricted  
3. **Large Repositories**: May take longer and require more memory  
4. **Rate Limits**: Using a GitHub token avoids hitting API limits  

### Performance Tips

- Use GitHub tokens for better API rate limits  
- Test on smaller repos first  
- Groq provides fast inference  
- FAISS ensures efficient similarity search  

---

## ðŸ–¼ RAG + Code Generation Pipeline

```text
                 ðŸŒ GitHub Repository
                          â”‚
                          â–¼
                ðŸ“‚ Repository Crawling                                     ðŸ’» Code Generation
        (GitHub API fetch + file filtering)                             (Prompt templates with Groq)
                          â”‚                                                          â”‚
                          â–¼                                                          |
              Advanced Document Processing                                           â”‚
       (Language-aware chunking & preprocessing)                                     â”‚
                          â”‚                                                          |
                          â–¼                                                          â–¼                                     
             Embedding Creation (HuggingFace)                                     User Input
                          â”‚                                                  (Get query from user)   
                          â–¼                                                          |        
              Vector Storage (FAISS Indexing)                                        |
                          â”‚                                                          |
                          |                                                          â”‚
                          â–¼                                                          |
                Query Processing (RAG Q&A)                               ðŸ›  Generated Code Snippets   
                (Retrieve relevant chunks)                            (Functions, scripts, examples)
                          â”‚                                                          |
                          â–¼                                                          | 
               LLM Response Generation                                               |
              (Groq LLM answers questions)                                           |
                          â”‚                                                          |
                           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>âœ… User Interface (Streamlit)âœ…<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Legend / Highlights:**
- ðŸŒ Source GitHub repo  
- ðŸ“‚ Crawling & filtering  
- ðŸ§  Language-specific processing  
- ðŸ”— Embeddings creation for semantic search  
- ðŸ“Š FAISS for fast retrieval  
- ðŸ“– Q&A for GitHub knowledge  
- ðŸ’» Code Generation using Groq LLM prompt templates  
- âœ… Streamlit interface for easy access  

---

## ðŸ“¦ Dependencies

- **streamlit**: Web interface  
- **langchain**: Document processing & splitting  
- **groq**: LLM inference  
- **sentence-transformers**: Embeddings  
- **faiss-cpu**: Vector similarity search  
- **requests**: GitHub API calls  

---

âœ… Now, you can **explore repositories, ask questions, and even generate code** all in one place!

